"""
4ë‹¨ê³„: BERT Attention Score ì¶”ì¶œ ë° ë­í‚¹
- BERTì˜ Attention Scoreë¥¼ í™œìš©í•˜ì—¬ ê° ë‹¨ì–´ì˜ ê°ì • ë¶„ë¥˜ ê¸°ì—¬ë„ë¥¼ ì¸¡ì •
- ì‹ ë¢°ë„ (confidence) ì €ì¥ ë¡œì§ í¬í•¨
"""

import os
import json
from pathlib import Path
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from collections import Counter
import numpy as np

# Step 3ì™€ ë™ì¼í•œ ëª¨ë¸ ì´ë¦„ ì¬ì‚¬ìš©
MODEL_NAME = "matthewburke/korean_sentiment" 


class BertAttentionRanker:
    """BERT Attention Score ê¸°ë°˜ ë‹¨ì–´ ì¤‘ìš”ë„ ì¶”ì¶œê¸°"""
    
    def __init__(self, morpheme_folder="output/morpheme", 
                 sentiment_folder="output/sentiment",
                 output_folder="output/attention"):
        
        self.morpheme_folder = morpheme_folder
        self.sentiment_folder = sentiment_folder
        self.output_folder = output_folder
        os.makedirs(output_folder, exist_ok=True)
        
        print(f"ğŸ¤– BERT Attention ëª¨ë¸ ({MODEL_NAME}) ë¡œë”© ì¤‘...")
        
        # ğŸš¨ ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€: í˜„ì¬ ì‹¤í–‰ ê²½ë¡œ í™•ì¸
        #print(f"DEBUG: í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ (CWD): {os.getcwd()}")
        #print(f"DEBUG: ì°¾ëŠ” Sentiment í´ë” ê²½ë¡œ: {os.path.join(os.getcwd(), sentiment_folder)}")

        try:
            self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
            self.model = AutoModelForSequenceClassification.from_pretrained(
                MODEL_NAME, 
                output_attentions=True
            )
            self.model.eval()
            print("âœ… BERT Attention ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        except Exception as e:
            raise Exception(f"âŒ BERT ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def load_json_file(self, file_path):
        """íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ JSON íŒŒì¼ì„ ë¡œë“œ"""
        try:
            if not os.path.exists(file_path):
                # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜
                return None
            
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            # íŒŒì¼ì€ ìˆì§€ë§Œ JSON í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ê¶Œí•œ ë¬¸ì œê°€ ìˆì„ ê²½ìš°
            print(f"âŒ JSON ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ ({file_path}): {e}")
            return None
        
    def get_document_text(self, filename):
        """ì›ë³¸ TXT íŒŒì¼ì„ ë¡œë“œ"""
        txt_path = os.path.join('data/txt_files', filename)
        if os.path.exists(txt_path):
            with open(txt_path, 'r', encoding='utf-8') as f:
                return f.read()
        return None

    def extract_and_rank(self, morpheme_filename):
        """ë‹¨ì¼ íŒŒì¼ Attention Score ì¶”ì¶œ ë° ë­í‚¹"""
        
        # 1. í•„ìˆ˜ ë°ì´í„° ë¡œë“œ
        morpheme_data = self.load_json_file(os.path.join(self.morpheme_folder, morpheme_filename))
        if not morpheme_data: 
            print(f"âš ï¸  {morpheme_filename} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Step 2ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return None
        
        # Sentiment íŒŒì¼ ê²½ë¡œ ìƒì„±
        sentiment_filename_derived = morpheme_filename.replace('_morpheme.json', '_sentiment.json')
        sentiment_path = os.path.join(self.sentiment_folder, sentiment_filename_derived)
        
        # ğŸš¨ ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€: ì°¾ëŠ” íŒŒì¼ ê²½ë¡œ ì¶œë ¥
        #print(f"DEBUG: Sentiment íŒŒì¼ì„ ì°¾ëŠ” ê²½ë¡œ: {sentiment_path}") 

        sentiment_data = self.load_json_file(sentiment_path)
        
        if not sentiment_data: 
            # íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¡œë“œì— ì‹¤íŒ¨í•˜ë©´ ì—¬ê¸°ì„œ ì¢…ë£Œ
            print(f"âš ï¸  {Path(sentiment_path).name} íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Step 3 ì‹¤í–‰ ë° ê²½ë¡œ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return None

        original_text = self.get_document_text(morpheme_data['filename'])
        if not original_text: return None

        print(f"\n{'='*60}")
        print(f"âœ¨ Attention Score ì¶”ì¶œ ì¤‘: {morpheme_filename}")
        print('='*60)

        # 2. í† í°í™” ë° Attention ì¶”ì¶œ (ëª¨ë¸ ì‹¤í–‰)
        inputs = self.tokenizer(original_text, return_tensors="pt", truncation=True, padding=True)
        
        with torch.no_grad():
            outputs = self.model(**inputs)
        
        # 3. Attention Score ê³„ì‚° 
        attentions = outputs.attentions 
        last_layer_att = attentions[-1][0].mean(dim=0)
        cls_attention = last_layer_att[0, :].cpu().numpy()

        tokens = self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
        
        # 4. ë‹¨ì–´ë³„ ì ìˆ˜ ë§¤í•‘ ë° ë­í‚¹
        token_importance = {}
        for i, token in enumerate(tokens[1:-1]):
            word = token.replace('##', '')
            score = float(cls_attention[i+1])
            
            if word not in token_importance:
                token_importance[word] = []
            token_importance[word].append(score)

        # 5. ìµœì¢… ë­í‚¹
        ranked_words = []
        all_morphemes = morpheme_data.get('all_nouns', []) + morpheme_data.get('all_verbs', []) + morpheme_data.get('all_adjectives', []) + morpheme_data.get('all_adverbs', []) + morpheme_data.get('all_interjections', [])
        
        for word, scores in token_importance.items():
            avg_score = np.mean(scores)
            
            if word in all_morphemes:
                ranked_words.append((word, avg_score))

        ranked_words.sort(key=lambda x: x[1], reverse=True)
        
        # 6. ê²°ê³¼ ì €ì¥
        bert_result = sentiment_data['bert_based']
        
        output_data = {
            'filename': morpheme_data['filename'],
            'bert_sentiment': bert_result['sentiment'],
            'bert_confidence': bert_result['confidence'], # ì‹ ë¢°ë„ ì €ì¥
            'top_attention_words': ranked_words[:30],
            'total_tokens_analyzed': len(tokens)
        }
        
        output_filename = Path(morpheme_filename).stem.replace('_morpheme', '_attention_rank.json')
        output_path = os.path.join(self.output_folder, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n    âœ… Top 10 ê¸°ì—¬ ë‹¨ì–´:")
        for word, score in ranked_words[:10]:
             print(f"       {word}: {score:.4f}")
        print(f"\n    ê²°ê³¼ ì €ì¥: {output_path}")

        return output_data
    
    def rank_all_files(self):
        """ì „ì²´ íŒŒì¼ Attention Score ì¶”ì¶œ"""
        morpheme_files = sorted([f for f in os.listdir(self.morpheme_folder) if f.endswith('_morpheme.json')])
        if not morpheme_files: return []
        
        results = []
        for filename in morpheme_files:
            result = self.extract_and_rank(filename)
            if result: results.append(result)
        
        return results


def main():
    print("\n 4ë‹¨ê³„: BERT Attention Score ì¶”ì¶œ ë° ë­í‚¹")
    try:
        ranker = BertAttentionRanker()
        
        choice = input("\nì‹¤í–‰ ëª¨ë“œ ì„ íƒ: 1. ë‹¨ì¼ íŒŒì¼ ë¶„ì„ / 2. ì „ì²´ íŒŒì¼ ë¶„ì„ (1-2): ").strip()
        
        if choice == '1':
            # íŒŒì¼ëª…ì„ ì…ë ¥í•  ë•Œ ë°˜ë“œì‹œ '.json'ê¹Œì§€ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
            filename = input("íŒŒì¼ëª… (ì˜ˆ: EG_001_morpheme.json): ").strip()
            ranker.extract_and_rank(filename)
        elif choice == '2':
            ranker.rank_all_files()
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒ")
    
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()