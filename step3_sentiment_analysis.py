"""
3Îã®Í≥Ñ: Í∞êÏ†ï Î∂ÑÏÑù
KNU Í∞êÏ†ïÏÇ¨Ï†Ñ Í∏∞Î∞ò Í∞êÏ†ï Î∂ÑÏÑù
"""

import os
import json
from pathlib import Path
from collections import Counter
import urllib.request


class SentimentAnalyzer:
    """Í∞êÏ†ï Î∂ÑÏÑùÍ∏∞ - KNU Í∞êÏ†ïÏÇ¨Ï†Ñ Í∏∞Î∞ò"""
    
    def __init__(self, morpheme_folder="output/morpheme", output_folder="output/sentiment"):
        self.morpheme_folder = morpheme_folder
        self.output_folder = output_folder
        os.makedirs(output_folder, exist_ok=True)
        
        print("Í∞êÏ†ï Î∂ÑÏÑùÍ∏∞ Ï¥àÍ∏∞Ìôî Ï§ë...")
        
        # Í∞êÏ†ïÏÇ¨Ï†Ñ Î°úÎìú
        self.sentiment_dict = self._load_sentiment_lexicon()
        
        print("‚úÖ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å!\n")
    
    def _download_lexicon(self):
        """KNU Í∞êÏ†ïÏÇ¨Ï†Ñ Îã§Ïö¥Î°úÎìú"""
        url = "https://raw.githubusercontent.com/park1200656/KnuSentiLex/master/SentiWord_Dict.txt"
        
        lexicon_dir = "data/sentiment"
        os.makedirs(lexicon_dir, exist_ok=True)
        
        lexicon_path = os.path.join(lexicon_dir, "SentiWord_Dict.txt")
        
        if os.path.exists(lexicon_path):
            return lexicon_path
        
        print("üì• Í∞êÏ†ïÏÇ¨Ï†Ñ Îã§Ïö¥Î°úÎìú Ï§ë...")
        try:
            urllib.request.urlretrieve(url, lexicon_path)
            print(f"‚úÖ Îã§Ïö¥Î°úÎìú ÏôÑÎ£å")
            return lexicon_path
        except Exception as e:
            print(f"‚ùå Îã§Ïö¥Î°úÎìú Ïã§Ìå®: {e}")
            return None
    
    def _load_sentiment_lexicon(self):
        """Í∞êÏ†ïÏÇ¨Ï†Ñ Î°úÎìú"""
        lexicon_path = self._download_lexicon()
        
        if not lexicon_path:
            print("‚ö†Ô∏è  Í∞êÏ†ïÏÇ¨Ï†Ñ ÏóÜÏù¥ ÏßÑÌñâ (Í∏∞Î≥∏ Í∞êÏ†ïÎã®Ïñ¥ ÏÇ¨Ïö©)")
            return self._get_basic_sentiment_dict()
        
        sentiment_dict = {}
        
        try:
            with open(lexicon_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        parts = line.strip().split('\t')
                        if len(parts) >= 2:
                            word = parts[0]
                            try:
                                polarity = float(parts[1])
                                sentiment_dict[word] = polarity
                            except:
                                continue
            
            print(f"‚úÖ Í∞êÏ†ïÏÇ¨Ï†Ñ Î°úÎìú: {len(sentiment_dict)}Í∞ú Îã®Ïñ¥")
            return sentiment_dict
        
        except Exception as e:
            print(f"‚ö†Ô∏è  Í∞êÏ†ïÏÇ¨Ï†Ñ Î°úÎìú Ïã§Ìå®: {e}")
            return self._get_basic_sentiment_dict()
    
    def _get_basic_sentiment_dict(self):
        """Í∏∞Î≥∏ Í∞êÏ†ï Îã®Ïñ¥ ÏÇ¨Ï†Ñ"""
        return {
            # Í∏çÏ†ï (+1)
            'Ï¢ãÎã§': 1.0, 'ÌñâÎ≥µÌïòÎã§': 1.0, 'Ìé∏ÏïàÌïòÎã§': 1.0, 'Ï¶êÍ≤ÅÎã§': 1.0,
            'Í∏∞ÏÅòÎã§': 1.0, 'ÎßåÏ°±Ïä§ÎüΩÎã§': 1.0, 'Ìé∏ÌïòÎã§': 1.0, 'Ïû¨ÎØ∏ÏûàÎã§': 1.0,
            
            # Î∂ÄÏ†ï (-1)
            'ÎÇòÏÅòÎã§': -1.0, 'Î∂àÏïàÌïòÎã§': -1.0, 'Ïä¨ÌîÑÎã§': -1.0, 'ÌûòÎì§Îã§': -1.0,
            'Ïö∞Ïö∏ÌïòÎã§': -1.0, 'Ïä§Ìä∏Î†àÏä§': -1.0, 'Î∂àÌé∏ÌïòÎã§': -1.0, 'ÎãµÎãµÌïòÎã§': -1.0
        }
    
    def analyze_text(self, words):
        """Îã®Ïñ¥ Î¶¨Ïä§Ìä∏ÏóêÏÑú Í∞êÏ†ï Î∂ÑÏÑù"""
        
        scores = []
        positive_words = []
        negative_words = []
        neutral_words = []
        
        for word in words:
            if word in self.sentiment_dict:
                score = self.sentiment_dict[word]
                scores.append(score)
                
                if score > 0:
                    positive_words.append((word, score))
                elif score < 0:
                    negative_words.append((word, score))
                else:
                    neutral_words.append(word)
        
        # Ï†ÑÏ≤¥ Í∞êÏ†ï Ï†êÏàò
        if scores:
            avg_score = sum(scores) / len(scores)
            total_score = sum(scores)
        else:
            avg_score = 0
            total_score = 0
        
        # Í∞êÏ†ï Î∂ÑÎ•ò
        if avg_score > 0.1:
            sentiment = "Í∏çÏ†ï"
        elif avg_score < -0.1:
            sentiment = "Î∂ÄÏ†ï"
        else:
            sentiment = "Ï§ëÎ¶Ω"
        
        return {
            'sentiment': sentiment,
            'avg_score': round(avg_score, 3),
            'total_score': round(total_score, 3),
            'positive_words': sorted(positive_words, key=lambda x: x[1], reverse=True),
            'negative_words': sorted(negative_words, key=lambda x: x[1]),
            'neutral_words': neutral_words,
            'emotion_word_count': len(scores)
        }
    
    def analyze_single_file(self, morpheme_filename):
        """Îã®Ïùº ÌòïÌÉúÏÜå Î∂ÑÏÑù Í≤∞Í≥º ÌååÏùºÏóêÏÑú Í∞êÏ†ï Î∂ÑÏÑù"""
        
        morpheme_path = os.path.join(self.morpheme_folder, morpheme_filename)
        
        if not os.path.exists(morpheme_path):
            print(f"‚ùå ÌååÏùº ÏóÜÏùå: {morpheme_path}")
            return None
        
        print(f"\n{'='*60}")
        print(f"üìÑ Í∞êÏ†ï Î∂ÑÏÑù Ï§ë: {morpheme_filename}")
        print('='*60)
        
        # ÌòïÌÉúÏÜå Î∂ÑÏÑù Í≤∞Í≥º Î°úÎìú
        try:
            with open(morpheme_path, 'r', encoding='utf-8') as f:
                morpheme_data = json.load(f)
        except Exception as e:
            print(f"‚ùå ÌååÏùº ÏùΩÍ∏∞ Ïã§Ìå®: {e}")
            return None
        
        # Î™®Îì† Îã®Ïñ¥ ÏàòÏßë (Î™ÖÏÇ¨, ÎèôÏÇ¨, ÌòïÏö©ÏÇ¨)
        all_words = []
        all_words.extend(morpheme_data.get('all_nouns', []))
        all_words.extend(morpheme_data.get('all_verbs', []))
        all_words.extend(morpheme_data.get('all_adjectives', []))
        
        print(f"   Î∂ÑÏÑùÌï† Îã®Ïñ¥ Ïàò: {len(all_words)}Í∞ú")
        
        # Í∞êÏ†ï Î∂ÑÏÑù
        result = self.analyze_text(all_words)
        
        print(f"\n   üìä Í∞êÏ†ï Î∂ÑÏÑù Í≤∞Í≥º:")
        print(f"      Í∞êÏ†ï: {result['sentiment']}")
        print(f"      ÌèâÍ∑† Ï†êÏàò: {result['avg_score']}")
        print(f"      Ï¥ùÏ†ê: {result['total_score']}")
        print(f"      Í∞êÏ†ï Îã®Ïñ¥: {result['emotion_word_count']}Í∞ú")
        
        if result['positive_words']:
            print(f"\n   üòä Í∏çÏ†ï Îã®Ïñ¥ (Top 5):")
            for word, score in result['positive_words'][:5]:
                print(f"      {word}: +{score}")
        
        if result['negative_words']:
            print(f"\n   üò¢ Î∂ÄÏ†ï Îã®Ïñ¥ (Top 5):")
            for word, score in result['negative_words'][:5]:
                print(f"      {word}: {score}")
        
        # Í≤∞Í≥º Ï†ÄÏû•
        output_data = {
            'filename': morpheme_data.get('filename', ''),
            'sentiment': result['sentiment'],
            'avg_score': result['avg_score'],
            'total_score': result['total_score'],
            'emotion_word_count': result['emotion_word_count'],
            'positive_words': result['positive_words'],
            'negative_words': result['negative_words'],
            'text_length': morpheme_data.get('text_length', 0)
        }
        
        output_filename = Path(morpheme_filename).stem.replace('_morpheme', '_sentiment.json')
        output_path = os.path.join(self.output_folder, output_filename)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n   üíæ Í≤∞Í≥º Ï†ÄÏû•: {output_path}")
        
        return output_data
    
    def analyze_all_files(self):
        """Î™®Îì† ÌòïÌÉúÏÜå Î∂ÑÏÑù ÌååÏùº Ï≤òÎ¶¨"""
        
        morpheme_files = sorted([
            f for f in os.listdir(self.morpheme_folder) 
            if f.endswith('_morpheme.json')
        ])
        
        if not morpheme_files:
            print(f"‚ùå ÌòïÌÉúÏÜå Î∂ÑÏÑù ÌååÏùº ÏóÜÏùå: {self.morpheme_folder}")
            print("   Î®ºÏ†Ä Step 2Î•º Ïã§ÌñâÌïòÏÑ∏Ïöî!")
            return []
        
        print(f"\nüìö Ï¥ù {len(morpheme_files)}Í∞ú ÌååÏùº Í∞êÏ†ï Î∂ÑÏÑù ÏãúÏûë")
        
        results = []
        for i, filename in enumerate(morpheme_files, 1):
            print(f"\n[{i}/{len(morpheme_files)}]")
            result = self.analyze_single_file(filename)
            if result:
                results.append(result)
        
        # Ï†ÑÏ≤¥ ÌÜµÍ≥Ñ
        if results:
            print(f"\n\n{'='*60}")
            print(f"üìä Ï†ÑÏ≤¥ ÌÜµÍ≥Ñ")
            print('='*60)
            
            sentiments = [r['sentiment'] for r in results]
            sentiment_counts = Counter(sentiments)
            
            print(f"\n   Í∞êÏ†ï Î∂ÑÌè¨:")
            for sentiment, count in sentiment_counts.items():
                percentage = (count / len(results)) * 100
                print(f"      {sentiment}: {count}Í∞ú ({percentage:.1f}%)")
            
            avg_scores = [r['avg_score'] for r in results]
            overall_avg = sum(avg_scores) / len(avg_scores)
            
            print(f"\n   Ï†ÑÏ≤¥ ÌèâÍ∑† Í∞êÏ†ï Ï†êÏàò: {overall_avg:.3f}")
            
            # Ï†ÑÏ≤¥ ÏöîÏïΩ Ï†ÄÏû•
            summary = {
                'total_files': len(results),
                'sentiment_distribution': dict(sentiment_counts),
                'overall_avg_score': round(overall_avg, 3),
                'files': [
                    {
                        'filename': r['filename'],
                        'sentiment': r['sentiment'],
                        'score': r['avg_score']
                    }
                    for r in results
                ]
            }
            
            summary_path = os.path.join(self.output_folder, 'sentiment_summary.json')
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            print(f"\n   üíæ Ï†ÑÏ≤¥ ÏöîÏïΩ Ï†ÄÏû•: {summary_path}")
        
        print(f"\n{'='*60}")
        print(f"‚úÖ Í∞êÏ†ï Î∂ÑÏÑù ÏôÑÎ£å!")
        print('='*60)
        
        return results


def main():
    print("\nüòä 3Îã®Í≥Ñ: Í∞êÏ†ï Î∂ÑÏÑù")
    
    try:
        analyzer = SentimentAnalyzer()
        
        print("\n1. Îã®Ïùº ÌååÏùº Î∂ÑÏÑù")
        print("2. Ï†ÑÏ≤¥ ÌååÏùº Î∂ÑÏÑù")
        
        choice = input("\nÏÑ†ÌÉù (1-2): ").strip()
        
        if choice == '1':
            filename = input("ÌååÏùºÎ™Ö (Ïòà: EG_001_morpheme.json): ").strip()
            analyzer.analyze_single_file(filename)
        elif choice == '2':
            analyzer.analyze_all_files()
        else:
            print("‚ùå ÏûòÎ™ªÎêú ÏÑ†ÌÉù")
    
    except Exception as e:
        print(f"\n‚ùå Ïò§Î•ò Î∞úÏÉù: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()